[
  {
    "objectID": "posts/20221115_AB_testing.html",
    "href": "posts/20221115_AB_testing.html",
    "title": "A/B Testing From Bayesian Point of View (1)",
    "section": "",
    "text": "A classical use-case of A/B tesing is optimizing the click through rate of a e-commerse website given different layout designs.\n\n\n\nDrawing 2022-11-15 14.14.30.excalidraw.png\n\n\nSome common questions we want to answer: - which layout is better ? - how many data should we collect ? - how much better ?\n\n\n\nAssuming layout 2 is better and we generate data according to this assumption. Let’s try to analyze the generated data to recover our assumption.\n\nfrom scipy.stats import bernoulli\n\nsize_1 = 100\nsize_2 = 100\n\n# the \"true\" CTR of both layouts\np_1 = 0.7\np_2 = 0.9\n\npopulation_1 = bernoulli.rvs(p_1, size=size_1)\npopulation_2 = bernoulli.rvs(p_2, size=size_2)\n\n\n\n\nLet’s model the CTR as a beta distribution since it is always between 0 and 1, and assume we know nothing about how the CTR look like and hence uniformly distributed across the interval [0,1]\n\nimport pymc as pm\nimport arviz as az\nimport matplotlib.pyplot as plt\n\naz.style.use(\"fivethirtyeight\")\n\n\nwith pm.Model() as model:\n    ctr1 = pm.Beta(\"ctr1\", alpha=1, beta=1)\n    ctr2 = pm.Beta(\"ctr2\", alpha=1, beta=1)\n    click1 = pm.Binomial(\"click1\", p=ctr1, n=size_1, observed=sum(population_1))\n    click2 = pm.Binomial(\"click2\", p=ctr2, n=size_2, observed=sum(population_2))\n    diff = pm.Deterministic(\"diff\", ctr2-ctr1)\n    t = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [ctr1, ctr2]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02<00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n\n\n\nfig, axs = plt.subplots(2, 1, figsize=(7, 7), sharex=True)\naz.plot_posterior(t.posterior[\"ctr1\"], ax=axs[0])\naxs[0].set_title(\"Click Trough Rate (Layout 1)\", fontsize=20)\naz.plot_posterior(t.posterior[\"ctr2\"], ax=axs[1])\naxs[1].set_title(C)\n\nText(0.5, 1.0, 'Click Trough Rate (Layout 2)')\n\n\n\n\n\n\naz.plot_posterior(t, var_names=[\"diff\"])\nplt.title(\"Difference between CTR\", fontsize=20)\n\nText(0.5, 1.0, 'Difference between CTR')"
  },
  {
    "objectID": "posts/20220912_testing.html",
    "href": "posts/20220912_testing.html",
    "title": "Central Limit Theorem - Misconception 1",
    "section": "",
    "text": "Example 1: Uniform Distribution\nSuppose we are given a dataset consists of numbers uniformly distributed between 0 and 1.\n\n\nCode\ndata = np.random.uniform(size=10000)\n_ = sns.histplot(data)\n\n\n\n\n\nFigure 1: the population is of uniform distribution\n\n\n\n\nWe can randomly sample 100 data points from the population and calculate the sample mean.\n\nsample = np.random.choice(data, 100)\nsample.mean()\n\n0.5453087847471367\n\n\nThe sample mean is a random variable because of the random sampling process.\n\nfor _ in range(5):\n    sample = np.random.choice(data, 100)\n    print(sample.mean())\n\n0.4780188476724967\n0.4884357038347728\n0.49375289478957385\n0.46197942889944293\n0.4611685890607802\n\n\nIf we run the sampling process 10000 times, and plot the distribution of the sample means, we can see that it is indeed approximately of normal distribution.\n\n\nCode\nsampling_means = []\nfor _ in range(10000):\n    sample = np.random.choice(data, 100)\n    mean = sample.mean()\n    sampling_means.append(mean)\n_ = sns.histplot(sampling_means)\n\n\n\n\n\nFigure 2: the sample mean is approximately of normal distribution\n\n\n\n\nAs we increase the sample size, we can see the sample mean is converging to the expected value: 0.5, that is, the sampling error decresases.\n\n\nCode\nsampling_means = []\nfor n in [100, 300, 500]:\n    for _ in range(10000):\n        sample = np.random.choice(data, n)\n        mean = sample.mean()\n        sampling_means.append({\"n\": str(n), \"data\": mean})\n\ndf = pd.DataFrame(sampling_means)\n_ = sns.displot(df, x=\"data\", kind=\"kde\", hue=\"n\")\n\n\n\n\n\nFigure 3: the sample mean distribution for different sample sizes\n\n\n\n\n\n\nExample 2: Highly Skewed Distribution\nBut the power of the Central Limit Theorem is that it can be applied to any distribution with a finite mean and standard deviation. So even if we are sampling from a highly skewed distribution, the sample mean itself is going to be of normal distribution, and hence balanced.\n\n\nCode\ndata = np.random.beta(5, 2, size=10000)\n_ = sns.histplot(data)\n\n\n\n\n\nFigure 4: the population is skewed to the right\n\n\n\n\n\n\nCode\nsampling_means = []\nfor _ in range(10000):\n    sample = np.random.choice(data, 200)\n    mean = sample.mean()\n    sampling_means.append(mean)\n_ = sns.histplot(sampling_means)\n\n\n\n\n\nFigure 5: the sample mean is approximately of normal distribution even if the population is skewed\n\n\n\n\n\n\nIntuition\nIn simple term, CLT can be expressed as\n\n\n\n\n\n\nCentral Limit Theorem\n\n\n\nThe sum of \\(n\\) independent random variables will be approximately a normal distribution provided that each has finite variance, and that no small set of the variables contributes most of the variation.\n\n\nIntuitively, if something is affected by many independent factors, that something will likely be uniformly distributed. For example, at least 180 genes contribute to human height, and we can assume that they are largely independent: gene A gives longer neck, gene B longer torso, gene C longer bones, etc. Human height is approximately normally distributed because it is caused by the sum of the independent effects of all these genes.\nThinking in this way, we can begin to see why normal distribution can be seen everywhere in the nature. It is because natural phenomena most likely have many independent small factors."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog Posts",
    "section": "",
    "text": "statistic\n\n\n\n\n\n\n\n\n\n\n\nNov 15, 2022\n\n\nCaleb\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nstatistic\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2022\n\n\nCaleb\n\n\n\n\n\n\nNo matching items"
  }
]